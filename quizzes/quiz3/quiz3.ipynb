{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> QTM 151 - Quiz 3 </span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to submit as an HTML file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\"> \n",
    "\n",
    "Print your Emory ID as a string below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2428993\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here\n",
    "print('2428993')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\" >\n",
    "This quiz is open book \n",
    "\n",
    "- You can use the lecture notes and the internet\n",
    "- You will get partial credit for attempting the questions\n",
    "- To get full credit, the code should run as intended\n",
    "- You should <span style=\"color:red\"> NOT </span> communicate with other students\n",
    "\n",
    "Print the following message: <br>\n",
    "\n",
    "\"I will abide by Emory's code of conduct\"\n",
    "\n",
    "\n",
    "**By printing the message, you acknowledge that you will abide by Emory's code of conduct.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will abide by Emory's code of conduct\n"
     ]
    }
   ],
   "source": [
    "# Write your answer here:\n",
    "print(\"I will abide by Emory's code of conduct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Import the libraries \"numpy\" and \"pandas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "(a) Replace the values of a column\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/sprint_results.csv\" file\n",
    "- Print the list with the unique values that are not numeric in the column \"positionText\"\n",
    "- Replace the non-numerica values (\"R\" and \"N\") with ```np.nan``` (missing value) in the column \"positionText\"\n",
    "- Create a new column \"positionNumeric\" that converts the modified \"positionText\" column from string to numeric using ```pd.to_numeric()```\n",
    "\n",
    "HINT: See the example in Lecture 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R' 'N']\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "data_sprint = pd.read_csv(\"data_raw/sprint_results.csv\")\n",
    "subset = data_sprint.query(\"positionText.str.isnumeric() == False\")\n",
    "list_unique = pd.unique(subset[\"positionText\"])\n",
    "print(list_unique)\n",
    "list_old = ['R','N']\n",
    "list_new = [np.nan, np.nan]\n",
    "data_sprint[\"positionText\"] = data_sprint[\"positionText\"].replace(list_old, list_new)\n",
    "data_sprint['positionNumeric'] = pd.to_numeric(data_sprint['positionText'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(b) Recode a numeric colum\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/races.csv\" file\n",
    "- Recode the \"year\" column into a new column \"year_brackets\" with the following categories\n",
    "\n",
    "$\\qquad$ ``` [\"1950-1974\",\"1975-1999\",\"2000-onwards\"] ```\n",
    "\n",
    "- Display the new \"year_brackets\" variable\n",
    "\n",
    "$\\qquad$ HINT: Use the \"pd.cut()\" command. See Lecture 12 (check the note in the example!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      year year_brackets\n",
      "0     2009  2000-onwards\n",
      "1     2009  2000-onwards\n",
      "2     2009  2000-onwards\n",
      "3     2009  2000-onwards\n",
      "4     2009  2000-onwards\n",
      "...    ...           ...\n",
      "1097  2023  2000-onwards\n",
      "1098  2023  2000-onwards\n",
      "1099  2023  2000-onwards\n",
      "1100  2023  2000-onwards\n",
      "1101  2023  2000-onwards\n",
      "\n",
      "[1102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "data_races = pd.read_csv('data_raw/races.csv')\n",
    "\n",
    "bins = [1949, 1974, 1999, data_races['year'].max()]\n",
    "labels = [\"1950-1974\", \"1975-1999\", \"2000-onwards\"]\n",
    "\n",
    "data_races['year_brackets'] = pd.cut(data_races['year'], bins=bins, labels=labels, right=True)\n",
    "\n",
    "print(data_races[['year', 'year_brackets']])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(c) Aggregate and query\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/sprint_results.csv\" file\n",
    "- Subset the observations for 'constructorId == 3' using ```.query()```\n",
    "- Obtain the sum of \"laps\" by \"driverId\" using ``` .groupby().agg() ```\n",
    "- Subset the drivers with a sum of laps $\\ge 40$\n",
    "- Store the results of all these operations in a dataframe ```sprint_results_agg ```\n",
    "- Display the ```sprint_results_agg``` dataframe\n",
    "- Provide a one-sentence explanation of the information in the ```sprint_results_agg ``` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driverId  laps\n",
      "0       847    59\n",
      "1       848    56\n",
      "2       849   127\n"
     ]
    }
   ],
   "source": [
    "data_sprint2 = pd.read_csv('data_raw/sprint_results.csv')\n",
    "subset2 = data_sprint2.query('constructorId == 3')\n",
    "data_grouped = subset2.groupby('driverId').agg({'laps': 'sum'})\n",
    "data_grouped_filtered = data_grouped[data_grouped['laps'] >= 40]\n",
    "sprint_results_agg = data_grouped_filtered.reset_index()\n",
    "print(sprint_results_agg)\n",
    "\n",
    "#Of those with constructorId being 3 and with more than 40 total laps, there are 3 drivers with Ids being (847, 848 and 849) \n",
    "#and their total laps are (59, 56 and 127) respectively. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(d) Aggregate and sort\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/sprint_results.csv\" file\n",
    "- Obtain the sum of \"laps\" by \"driverId\" using ``` .groupby().agg() ```\n",
    "- Sort the teams in descending order using of the sum of laps using ``` .sort_values() ```\n",
    "- Display your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          laps\n",
      "driverId      \n",
      "1          127\n",
      "832        127\n",
      "854        127\n",
      "852        127\n",
      "849        127\n",
      "847        127\n",
      "846        127\n",
      "844        127\n",
      "839        127\n",
      "840        127\n",
      "830        127\n",
      "822        127\n",
      "817        127\n",
      "815        126\n",
      "20         125\n",
      "842        109\n",
      "4          104\n",
      "825         68\n",
      "841         59\n",
      "853         59\n",
      "848         56\n",
      "855         47\n",
      "8           41\n",
      "9           18\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "data_sprint3 = pd.read_csv(\"data_raw/sprint_results.csv\")\n",
    "\n",
    "data_agg = data_sprint3.groupby('driverId').agg({'laps':'sum'})\n",
    "sorted_df = data_agg.sort_values(by='laps', ascending=False)\n",
    "print(sorted_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(e) Rename column\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/sprint_results.csv\" file\n",
    "- Rename the column \"points\" to \"points_sprint\"\n",
    "- Display the dataframe columns\n",
    "\n",
    "HINT: Create a dictionary and use ```.rename(columns = ...)``` See Lecture 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid',\n",
      "       'position', 'positionText', 'positionOrder', 'points_sprint', 'laps',\n",
      "       'time', 'milliseconds', 'fastestLap', 'fastestLapTime', 'statusId'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "data_sprint4 = pd.read_csv(\"data_raw/sprint_results.csv\")\n",
    "rename_value = {'points': 'points_sprint'}\n",
    "df = data_sprint4.rename(columns=rename_value)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(f) Merge dataset\n",
    "\n",
    "<font size = \"3\">\n",
    "\n",
    "- Import the \"data_raw/sprint_results.csv\" and \"data_raw/constructors.csv\" files\n",
    "- Create a new dataset with  ```pd.merge()``` using \"sprint_results\" as the primary dataset (left), and \"constructors\" as the secondary dataset (right), merging on the column \"constructorId\"\n",
    "- To get full points **ONLY** merge the \"url\" column from the secondary dataset (not all the columns)\n",
    "- Display the resulting dataframe \n",
    "\n",
    "\n",
    "HINT: Use ```[[...]]``` to extract a subset of columns from the secondary dataset before merging, including the \"constructorId\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     resultId  raceId  driverId  constructorId  number  grid position  \\\n",
      "0           1    1061       830              9      33     2        1   \n",
      "1           2    1061         1            131      44     1        2   \n",
      "2           3    1061       822            131      77     3        3   \n",
      "3           4    1061       844              6      16     4        4   \n",
      "4           5    1061       846              1       4     6        5   \n",
      "..        ...     ...       ...            ...     ...   ...      ...   \n",
      "115       116    1095       840            117      18    15       16   \n",
      "116       117    1095       839            214      31     6       17   \n",
      "117       118    1095         4            214      14     7       18   \n",
      "118       119    1095       849              3       6    16       19   \n",
      "119       120    1095       848              3      23    11       \\N   \n",
      "\n",
      "    positionText  positionOrder  points  laps       time milliseconds  \\\n",
      "0              1              1       3    17  25:38.426      1538426   \n",
      "1              2              2       2    17     +1.430      1539856   \n",
      "2              3              3       1    17     +7.502      1545928   \n",
      "3              4              4       0    17    +11.278      1549704   \n",
      "4              5              5       0    17    +24.111      1562537   \n",
      "..           ...            ...     ...   ...        ...          ...   \n",
      "115           16             16       0    24    +50.700      1862007   \n",
      "116           17             17       0    24    +51.756      1863063   \n",
      "117           18             18       0    24    +53.985      1865292   \n",
      "118           19             19       0    24  +1:16.850      1888157   \n",
      "119            R             20       0    12         \\N           \\N   \n",
      "\n",
      "    fastestLap fastestLapTime  statusId  \\\n",
      "0           14       1:30.013         1   \n",
      "1           17       1:29.937         1   \n",
      "2           17       1:29.958         1   \n",
      "3           16       1:30.163         1   \n",
      "4           16       1:30.566         1   \n",
      "..         ...            ...       ...   \n",
      "115          4       1:15.425         1   \n",
      "116          5       1:16.097         1   \n",
      "117          5       1:14.764         1   \n",
      "118          4       1:16.525         1   \n",
      "119          4       1:15.998        31   \n",
      "\n",
      "                                                   url  \n",
      "0         http://en.wikipedia.org/wiki/Red_Bull_Racing  \n",
      "1    http://en.wikipedia.org/wiki/Mercedes-Benz_in_...  \n",
      "2    http://en.wikipedia.org/wiki/Mercedes-Benz_in_...  \n",
      "3        http://en.wikipedia.org/wiki/Scuderia_Ferrari  \n",
      "4                 http://en.wikipedia.org/wiki/McLaren  \n",
      "..                                                 ...  \n",
      "115  http://en.wikipedia.org/wiki/Aston_Martin_in_F...  \n",
      "116        http://en.wikipedia.org/wiki/Alpine_F1_Team  \n",
      "117        http://en.wikipedia.org/wiki/Alpine_F1_Team  \n",
      "118  http://en.wikipedia.org/wiki/Williams_Grand_Pr...  \n",
      "119  http://en.wikipedia.org/wiki/Williams_Grand_Pr...  \n",
      "\n",
      "[120 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# Write your own code\n",
    "all_sprint_results = pd.read_csv(\"data_raw/sprint_results.csv\")\n",
    "all_constructors = pd.read_csv(\"data_raw/constructors.csv\")\n",
    "\n",
    "\n",
    "constructors_subset = all_constructors[['constructorId', 'url']]\n",
    "\n",
    "df_merged = pd.merge(all_sprint_results, constructors_subset, on='constructorId', how='left')\n",
    "\n",
    "print(df_merged)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
